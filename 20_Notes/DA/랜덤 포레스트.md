---
Created: 2023-10-22 22:29
tags:
  - AI/머신러닝
aliases:
---

# 개요
랜덤 포레스트는 [[지도학습]] 학습 중 분류 또는 회기에 모두를 수행할 수 있는 알고리즘이다.

[[의사결정 트리 분석]] 기반의 알고리즘으로 다수의 의사결정 트리들을 배깅하여 분류 또는 회귀를 수행하는 [[앙상블 분석|앙상블 기법]] 중 하나이다. 각 트리는 학습 데이터 중 서로 다른 데이터를 샘플링하여, 일부 데이터를 제외한 후 최적의 특징을 찾아 트리를 분기한다.

# 내용

### 알고리즘
- 개요
	- 다수의 의사결정 트리들을 배깅하여 분류 또는 회귀를 수행하는 [[앙상블 분석|앙상블 기법]]이다. 
	- 각 트리는 학습 데이터 중 서로 다른 데이터를 샘플링하여 일부 데이터를 제외한 후 최적의 특징을 찾아 트리를 분기한다.
- 특징
	- 다양한 분야에서 비교적 좋은 성능을 보여준다.
	- 트리들이 서로 조금씩 다른 특성을 갖게 되어 일반화 성능을 향상할 수 있다.
	- 샘플링을 하는 과정에서 한 샘플이 중복되어 추출될 수도 있다.
- 과정
	- 배깅의 일종으로 배깅에 변수 랜덤 선택 과정을 추가한 것이다.
	- 랜덤 포레스트는 의사결정 트리 기반의 알고리즘으로 여러개의 의사결정 트리가 모여 랜덤 포레스트를 이루는 구조다.
	- 랜덤 포레스트의 가장 큰 특징은 변수를 랜덤하게 선택하여 각 의사결정 트리를 학습시킨다는 것이다. 
	- [[부트스트랩(Bootstrap)|부트스트랩]] 방식을 통해 변수를 선택하므로 입력변수가 아주 많은 경우에도 변수를 제거하지 않고 분석하는 것이 가능하다.![[앙상블 분석_랜덤포레스트 과정.png]]

### 분석 수행
#### 랜덤 포레스트 - 분류 분석
- 분석 목표
	- 타이타닉 데이터셋에서 탑승자들의 생존여부(Survived)를 예측
- 접근 방법
	- 불필요한 속성을 제거하고 전처리과정을 거친 후,
	- 사이킷런의 랜덤 포레스트 알고리즘을 이용하여 학습 모델을 구축한 후 예측을 수행한다.
	- 랜덤 포레스트 알고리즘에서 사용할 트리 모델의 개수(n_estimators)와 개별 트리의 깊이(max_depth) 매개변수 값을 잘 조절하여 예측의 정확도를 높인다.

###### 필요 패키지 임포트
~~~ python
## 랜덤 포레스트(Random Forest) 알고리즘

## 1. 필요 패키지 임포트
import numpy as np
import pandas as pd
import sklearn

# 랜덤 포레스트 분류모델을 위한 패키지 임포트
from sklearn.ensemble import RandomForestClassifier
# 학습 및 테스트 데이터 분리를 위한 패키지 임포트
from sklearn.model_selection import train_test_split
~~~

###### 데이터 불러오기 
~~~ python
## 2. 데이터 불러오기
df = pd.read_csv("http://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv")
~~~

###### 데이터 탐색하기
~~~ python
## 3. 데이터 살펴보기
df.info()
df.describe()
~~~

###### 데이터 전처리
- 사이킷런의 LabelEncoder() 함수를 사용하여 라벨 인코딩을 수행
	- 텍스트로 되어있는 Sex컬럼은 숫자 0(female), 1(male)로 변환하는 레이블 인코딩을 수행한다.
	- Embarked 역시 인코딩을 수행하며, 사이킷런의 LabelEncoder() 함수를 사용한다.
	- LabelEncoder를 객체로 생성한 후 fit_transform() 함수를 사용해서 구현한다.
~~~ python
## 4. 데이터 전처리
# Age 컬럼의 결측값을 평균으로 대치한다.
d_mean = df["Age"].mean()
df["Age"].fillna(d_mean, inplace=True)

# Embarked 컬럼의 결측값을 최빈값으로 대치한다.
d_mode = df["Embarked"].mode()[0]
df["Embarked"].fillna(d_mode, inplace=True)

# Sex 컬럼의 값을 1과 0으로 레이블인코딩 한다.
from sklearn.preprocessing import LabelEncoder
df["Sex"] = LabelEncoder().fit_transform(df["Sex"])

# Embarked 컬럼의 값에 레이블인코딩 한다.
from sklearn.preprocessing import LabelEncoder
df["Embarked"] = LabelEncoder().fit_transform(df["Embarked"])

# SibSp, Parch의 값을 더해서 FamilySize 컬럼(파생변수)를 생성한다.
df["FamilySize"] = df["SibSp"]+df["Parch"]
~~~

###### 분석 데이터셋 준비
~~~ python
## 5. 분석 데이터셋 준비
# X는 독립변수(설명변수), y는 종속변수(목표변수)
X = df[["Pclass","Age","Fare","Embarked","FamilySize"]]
y = df["Survived"]

# 분석 데이터셋 분할(8:2)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
~~~

###### 데이터분석 수행
- 주어진 데이터로 탑승자의 생존을 구분하는 분류문제이다.
- 분류를 위한 알고리즘 중에서 랜덤 포레스트를 이용
	- 사이킷런의 랜덤 포레스트인 RandomForestClassifier를 사용한다.
	- RandomForestClassifier 객체를 생성하고 fit() 함수에 학습용 데이터(X_train)와 결정값 데이터(y_train)를 입력해 호출하면 학습이 수행된다.
- 학습이 완료된 rf 객체에서 테스트 데이터셋으로 분류(예측) 수행
~~~ python
## 6. 데이터 분석 수행
# RandomForestClassifier 객체 생성
rf = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=20)
rf.fit(X_train, y_train)          # 학습 수행

# 학습이 완료된 rf객체에서 테스트 데이터셋으로 예측 수행
pred = rf.predict(X_test)
~~~

###### 성능평가 및 시각화
- 정확도 측정을 위한 사이킷런의 accuracy_score() 함수 사용
	- 예측 정확도는 86%임을 알 수 있다.
~~~ python
## 7. 성능평가 및 시각화
# 모델 성능 - 정확도 측정
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, pred)
print(acc)
~~~

~~~
0.860333519
~~~

#### 랜덤 포레스트 - 회귀 분석
- 분석 목표
	- 1999년 미국 캘리포니아 인구가구 통계 데이터셋에서 주택중위가치(median_house_value)에 영향을 주는 변수들을 찾아보고, 이 변수들을 포함하는 트리모델을 생성하여 성능을 평가해본다.
- 접근 방법
	- 종속변수는 median_house_value로 한다.
	- 상관성이 있다고 판단되는 변수를 성택한 후 각각에 대해 랜덤 포레스트 알고리즘을 적용하여 모델을 생성한다.
	- 평균제곱오차(MSE) 값을 구해서 모델의 성능을 평가한다.
###### 필요 패키지 임포트
~~~python
## 랜덤 포레스트 알고리즘
import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt       # 맷플롯립 패키지 임포트

## 1. 데이터 임포트
# 랜덤 포레스트 모델을 위한 패키지 임포트
from sklearn.ensemble import RandomForestRegressor
# 학습 및 테스트 데이터셋 분리를 위한 패키지 임포트
from sklearn.model_selection import train_test_split
~~~
###### 데이터 불러오기
~~~python
## 2. 데이터 불러오기
df = pd.read_csv("https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv")
~~~
###### 데이터 탐색하기 
~~~python
## 3. 데이터 살펴보기
df.info()
~~~
###### 데이터 전처리
- 변수들의 상관관계 분석시에 median_income을 제외하면 median_house_value 와의 상관성이 낮은 것을 알 수 있다.
- 전체 컬럼을 독립변수로 사용해 분석을 수행해 본다.
~~~python
## 4. 데이터 전처리
# 결측값이 있는 행전체 제거 (axis가 1이면 열을 제거)
df = df.dropna(axis=0)

# ocean_proximity는 범주형 값으로 분석에서 제외
df = df.drop("ocean_proximity", axis=1)

# 변수들 간의 상관관계 분석
corr = df.corr(method="pearson")
print(corr)
~~~

~~~
                    median_house_value  
longitude                    -0.045398  
latitude                     -0.144638  
housing_median_age            0.106432  
total_rooms                   0.133294  
total_bedrooms                0.049686  
population                   -0.025300  
households                    0.064894  
median_income                 0.688355  
median_house_value            1.000000  
~~~

###### 분석 데이터셋 준비
~~~python
## 5. 분석 데이터셋 준비
# median_house_value를 제외한 나머지를 독립변수로 함
X = df.drop("median_house_value", axis=1)
y = df["median_house_value"]        # 종속변수(목표변수)

# 분석 데이터셋 분할(7:3)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
~~~

~~~
(14303, 8)
(6130, 8)
(14303,)
(6130,)
~~~
###### 데이터 분석 수행
- 사이킷런의 랜덤 포레스트 분석 모듈인 RandomForestRegressor 을 사용
- 학습이 완료된 rfr 객체에서 테스트 데이터셋으로 예측을 수행
~~~python
## 6. 데이터 분석 수행
# RandomForestRegressor 객체 생성
rfr = RandomForestRegressor(max_depth=3, random_state=42)
rfr.fit(X_train, y_train)         # 학습 수행
        
# 학습이 완료된 rfr 객체에서 테스트 데이터셋으로 예측 수행
pred = rfr.predict(X_test)
~~~
###### 성능평가 및 시각화
- 랜덤 포레스트 분석의 평가는 평균제곱오차(MSE)로 예측 정확도를 판단할 수 있따. MSE 값이 작을수록 모형의 예측 능력이 좋다고 판단한다.
- 사이킷런의 mean_squared_error() 함수로 정확도 측정
	- MSE 값이 높게 나왔으나 이는 앞에서 구현한 의사결정트리(6793101269)보다 다소 낮은 값으로 예측력이 개선되었음을 확인할 수 있다.
~~~python
## 7. 성능평가 및 시각화
# 모델 성능 평가 - 테스트 데이터셋
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, pred)
print(mse)
~~~

~~~
6447828605.376922
~~~


# 출처


# 관련 노트


# 외부 링크

