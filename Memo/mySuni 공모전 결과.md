
F1-Score
- 1회차 : 0.6487935656836461
	- 접근방법
		- 기본 구문 실행
	- 시도해볼 부분
		- 전처리 방식 개선
			- 학습데이터에서 제공한 Timestamp 데이터를 분할하여 학습데이터에 추가
		- 학습모델 추가
			- 다양한 분류모델 적용
				- 로지스틱 회귀분석
				- SVM
				- 랜덤포레스트
				- xgboost
		- 모델 하이퍼파라미터 조정
			- 위 모델 적용안 중에서 F1-Score가 높게 확보되는 모델에 대해 추가 검토
- 2회차 : 0.6057142857142856
	- 접근방법
		- 로지스틱회귀분석 모델 제출
- 3회차 : 0.7161290322580645
	- 접근방법
		- 랜덤포레스트 모델 제출
- 4회차 : 0.7309941520467838
	- 접근방법
		- xgboost 모델 제출
- 5회차 : 0.7272727272727273
	- 접근방법
		-  xgboost 모델 하이퍼파라미터 조정 (n_estimators=50)
- 6회차 : 0.7309941520467838
	- 접근방법
		-  xgboost 모델 하이퍼파라미터 재조정 (n_estimators=100)
		- Timestamp 프로퍼티 일부 추가하여 모델 업데이트
- 7회차 : 0.735042735042735
	- 접근방법
		- lightgbm 적용
- 8회차 : 0.6990881458966565
	- 접근방법
		- catboost 적용
- 10회차 : 0.735042735042735
	- 접근방법
		-  lightgbm 재적용
- 11회차 :
	- 접근방법
		- F1 Score를 향상시키는 추가 방법
			- Class Weight 조정: 불균형 데이터셋에서는 모델이 자주 등장하는 클래스를 더 많이 예측할 가능성이 있으므로, 각 클래스에 가중치를 부여하여 이를 조정할 수 있습니다. 예를 들어, class_weight='balanced'를 사용하면 각 클래스의 빈도수에 따라 가중치를 자동으로 조정합니다.
			- Resampling 기법: 데이터셋에서 오버샘플링(소수 클래스의 데이터를 복제) 또는 언더샘플링(다수 클래스의 데이터를 줄여서 균형 맞추기) 기법을 사용하여 클래스 불균형 문제를 해결할 수 있습니다.
			- 앙상블 기법: 여러 개의 분류기를 앙상블하여 예측 성능을 높일 수 있습니다. 예를 들어, VotingClassifier나 StackingClassifier를 사용하여 여러 모델의 예측을 결합하면 F1 Score가 개선될 수 있습니다.
			- Threshold 조정: Precision-Recall Curve를 사용하여 결정 임계값(threshold)을 조정함으로써 F1 Score를 최적화할 수 있습니다.



